{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_owid_2_analysis_NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAKdprYSwUh6IXsv/xGIY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w-oke/covid_reproduction/blob/main/covid_owid_2_analysis_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcknS606OT5D"
      },
      "source": [
        "The data loaded in this Notebook is based on the output of: covid_owid_1_preparation.ipynb, which can be accessed from:\n",
        "https://github.com/w-oke/covid_reproduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIXW7GbeaT8u"
      },
      "source": [
        "PYTHONHASHSEED=0\n",
        "import urllib.request\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laGKjQDkPOML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09b39d8-9a5c-41a1-fbd0-9a18b6d65ca9"
      },
      "source": [
        "df_link = 'https://github.com/w-oke/covid_reproduction/raw/main/covid_owid_df.parquet'\n",
        "df1 = pd.read_parquet(df_link)\n",
        "df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14671 entries, 0 to 14670\n",
            "Data columns (total 30 columns):\n",
            " #   Column                               Non-Null Count  Dtype         \n",
            "---  ------                               --------------  -----         \n",
            " 0   iso_code                             14671 non-null  object        \n",
            " 1   location                             14671 non-null  object        \n",
            " 2   date                                 14671 non-null  datetime64[ns]\n",
            " 3   reproduction_rate                    14671 non-null  float64       \n",
            " 4   new_tests_smoothed_per_thousand      14671 non-null  float64       \n",
            " 5   people_vaccinated_per_hundred        14671 non-null  float64       \n",
            " 6   people_fully_vaccinated_per_hundred  14671 non-null  float64       \n",
            " 7   total_boosters_per_hundred           14671 non-null  float64       \n",
            " 8   stringency_index                     14671 non-null  float64       \n",
            " 9   population_density                   14671 non-null  float64       \n",
            " 10  median_age                           14671 non-null  float64       \n",
            " 11  gdp_per_capita                       14671 non-null  float64       \n",
            " 12  extreme_poverty                      14671 non-null  float64       \n",
            " 13  handwashing_facilities               14671 non-null  float64       \n",
            " 14  hospital_beds_per_thousand           14671 non-null  float64       \n",
            " 15  life_expectancy                      14671 non-null  float64       \n",
            " 16  human_development_index              14671 non-null  float64       \n",
            " 17  Alpha                                14671 non-null  float64       \n",
            " 18  Beta                                 14671 non-null  float64       \n",
            " 19  Delta                                14671 non-null  float64       \n",
            " 20  Epsilon                              14671 non-null  float64       \n",
            " 21  Eta                                  14671 non-null  float64       \n",
            " 22  Gamma                                14671 non-null  float64       \n",
            " 23  Iota                                 14671 non-null  float64       \n",
            " 24  Kappa                                14671 non-null  float64       \n",
            " 25  Lambda                               14671 non-null  float64       \n",
            " 26  Mu                                   14671 non-null  float64       \n",
            " 27  Omicron                              14671 non-null  float64       \n",
            " 28  non_who                              14671 non-null  float64       \n",
            " 29  date_diff                            14671 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(27), object(2)\n",
            "memory usage: 3.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "7KM7x1gqExM-",
        "outputId": "8e8d16ca-3740-47fd-aa7b-f94e0ddc9898"
      },
      "source": [
        "df1.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reproduction_rate</th>\n",
              "      <th>new_tests_smoothed_per_thousand</th>\n",
              "      <th>people_vaccinated_per_hundred</th>\n",
              "      <th>people_fully_vaccinated_per_hundred</th>\n",
              "      <th>total_boosters_per_hundred</th>\n",
              "      <th>stringency_index</th>\n",
              "      <th>population_density</th>\n",
              "      <th>median_age</th>\n",
              "      <th>gdp_per_capita</th>\n",
              "      <th>extreme_poverty</th>\n",
              "      <th>handwashing_facilities</th>\n",
              "      <th>hospital_beds_per_thousand</th>\n",
              "      <th>life_expectancy</th>\n",
              "      <th>human_development_index</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Beta</th>\n",
              "      <th>Delta</th>\n",
              "      <th>Epsilon</th>\n",
              "      <th>Eta</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>Iota</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>Lambda</th>\n",
              "      <th>Mu</th>\n",
              "      <th>Omicron</th>\n",
              "      <th>non_who</th>\n",
              "      <th>date_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "      <td>14671.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.981247</td>\n",
              "      <td>0.024932</td>\n",
              "      <td>0.142838</td>\n",
              "      <td>0.114042</td>\n",
              "      <td>0.021666</td>\n",
              "      <td>0.560950</td>\n",
              "      <td>0.015554</td>\n",
              "      <td>0.473407</td>\n",
              "      <td>0.156399</td>\n",
              "      <td>0.134494</td>\n",
              "      <td>0.681668</td>\n",
              "      <td>0.199699</td>\n",
              "      <td>0.587462</td>\n",
              "      <td>0.590860</td>\n",
              "      <td>0.135999</td>\n",
              "      <td>0.031464</td>\n",
              "      <td>0.278307</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.005016</td>\n",
              "      <td>0.021805</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.006041</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.510628</td>\n",
              "      <td>0.510624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.309696</td>\n",
              "      <td>0.059803</td>\n",
              "      <td>0.224880</td>\n",
              "      <td>0.209447</td>\n",
              "      <td>0.066831</td>\n",
              "      <td>0.185213</td>\n",
              "      <td>0.078171</td>\n",
              "      <td>0.280223</td>\n",
              "      <td>0.168096</td>\n",
              "      <td>0.241245</td>\n",
              "      <td>0.314402</td>\n",
              "      <td>0.175682</td>\n",
              "      <td>0.230449</td>\n",
              "      <td>0.272662</td>\n",
              "      <td>0.240658</td>\n",
              "      <td>0.101743</td>\n",
              "      <td>0.407454</td>\n",
              "      <td>0.013383</td>\n",
              "      <td>0.031222</td>\n",
              "      <td>0.079873</td>\n",
              "      <td>0.017536</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.039937</td>\n",
              "      <td>0.040701</td>\n",
              "      <td>0.019252</td>\n",
              "      <td>0.443168</td>\n",
              "      <td>0.289618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.030000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.002293</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435200</td>\n",
              "      <td>0.001848</td>\n",
              "      <td>0.208459</td>\n",
              "      <td>0.032584</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.443836</td>\n",
              "      <td>0.068613</td>\n",
              "      <td>0.413206</td>\n",
              "      <td>0.355240</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026047</td>\n",
              "      <td>0.259259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009071</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>0.003167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.564800</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.468278</td>\n",
              "      <td>0.099553</td>\n",
              "      <td>0.012903</td>\n",
              "      <td>0.858901</td>\n",
              "      <td>0.153285</td>\n",
              "      <td>0.633403</td>\n",
              "      <td>0.632327</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500050</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.150000</td>\n",
              "      <td>0.025561</td>\n",
              "      <td>0.214730</td>\n",
              "      <td>0.119361</td>\n",
              "      <td>0.003309</td>\n",
              "      <td>0.703700</td>\n",
              "      <td>0.010465</td>\n",
              "      <td>0.740181</td>\n",
              "      <td>0.228384</td>\n",
              "      <td>0.127742</td>\n",
              "      <td>0.906227</td>\n",
              "      <td>0.270073</td>\n",
              "      <td>0.755602</td>\n",
              "      <td>0.813499</td>\n",
              "      <td>0.177391</td>\n",
              "      <td>0.023175</td>\n",
              "      <td>0.732812</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.012787</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.003552</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.765432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.190000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reproduction_rate  ...     date_diff\n",
              "count       14671.000000  ...  14671.000000\n",
              "mean            0.981247  ...      0.510624\n",
              "std             0.309696  ...      0.289618\n",
              "min            -0.030000  ...      0.000000\n",
              "25%             0.830000  ...      0.259259\n",
              "50%             1.000000  ...      0.518519\n",
              "75%             1.150000  ...      0.765432\n",
              "max             4.190000  ...      1.000000\n",
              "\n",
              "[8 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwUVoHhRPN8S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyimQktVeszY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda838ef-c0e4-490e-8ec2-de54a9076a79"
      },
      "source": [
        "# import the dictionary var with lists of features:\n",
        "var_link = 'https://github.com/w-oke/covid_reproduction/raw/main/covid_owid_var_dictionary.pkl'\n",
        "a_file = \"covid_owid_var_dictionary.pkl\"\n",
        "data = urllib.request.urlretrieve(var_link, a_file) # download the file\n",
        "with open(a_file, 'rb') as f:\n",
        "        var = pickle.load(f)\n",
        "\n",
        "print('The keys of the \\'var\\' dict are: ', var.keys())\n",
        "print()\n",
        "var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The keys of the 'var' dict are:  dict_keys(['y', 'meta', 'number', 'variants', 'scale', 'vaccine', 'imputer_no_date', 'imputer_date'])\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'imputer_date': ['new_tests_smoothed_per_thousand',\n",
              "  'people_vaccinated_per_hundred',\n",
              "  'people_fully_vaccinated_per_hundred',\n",
              "  'total_boosters_per_hundred',\n",
              "  'gdp_per_capita',\n",
              "  'hospital_beds_per_thousand',\n",
              "  'stringency_index',\n",
              "  'date_diff'],\n",
              " 'imputer_no_date': ['population_density',\n",
              "  'median_age',\n",
              "  'gdp_per_capita',\n",
              "  'extreme_poverty',\n",
              "  'handwashing_facilities',\n",
              "  'hospital_beds_per_thousand',\n",
              "  'life_expectancy',\n",
              "  'human_development_index'],\n",
              " 'meta': ['date', 'iso_code', 'location'],\n",
              " 'number': ['new_tests_smoothed_per_thousand',\n",
              "  'people_vaccinated_per_hundred',\n",
              "  'people_fully_vaccinated_per_hundred',\n",
              "  'total_boosters_per_hundred',\n",
              "  'stringency_index',\n",
              "  'population_density',\n",
              "  'median_age',\n",
              "  'human_development_index',\n",
              "  'gdp_per_capita',\n",
              "  'extreme_poverty',\n",
              "  'handwashing_facilities',\n",
              "  'hospital_beds_per_thousand',\n",
              "  'life_expectancy'],\n",
              " 'scale': ['new_tests_smoothed_per_thousand',\n",
              "  'people_vaccinated_per_hundred',\n",
              "  'people_fully_vaccinated_per_hundred',\n",
              "  'total_boosters_per_hundred',\n",
              "  'stringency_index',\n",
              "  'population_density',\n",
              "  'median_age',\n",
              "  'human_development_index',\n",
              "  'gdp_per_capita',\n",
              "  'extreme_poverty',\n",
              "  'handwashing_facilities',\n",
              "  'hospital_beds_per_thousand',\n",
              "  'life_expectancy',\n",
              "  'Alpha',\n",
              "  'Beta',\n",
              "  'Delta',\n",
              "  'Epsilon',\n",
              "  'Eta',\n",
              "  'Gamma',\n",
              "  'Iota',\n",
              "  'Kappa',\n",
              "  'Lambda',\n",
              "  'Mu',\n",
              "  'Omicron',\n",
              "  'non_who',\n",
              "  'date_diff'],\n",
              " 'vaccine': ['people_vaccinated_per_hundred',\n",
              "  'people_fully_vaccinated_per_hundred',\n",
              "  'total_boosters_per_hundred'],\n",
              " 'variants': ['Alpha',\n",
              "  'Beta',\n",
              "  'Delta',\n",
              "  'Epsilon',\n",
              "  'Eta',\n",
              "  'Gamma',\n",
              "  'Iota',\n",
              "  'Kappa',\n",
              "  'Lambda',\n",
              "  'Mu',\n",
              "  'Omicron',\n",
              "  'non_who'],\n",
              " 'y': ['reproduction_rate']}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sknNv1_-GXH"
      },
      "source": [
        "# allocate 10% of the data set to testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                        df1[var['number']+var['variants']], df1[var['y']], \n",
        "                        test_size=0.2, random_state=1)\n",
        "\n",
        "# allocate 25% of the remaining examples (20% of the dataset) to validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "                        X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-r_AKeWG4bL"
      },
      "source": [
        "# create a DNN model with 3 fully connected layers with 64 units each\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(units=128, activation='relu'),\n",
        "                          keras.layers.Dropout(0.15), # adding Dropout layers helps avoid overfitting\n",
        "                          keras.layers.Dense(units=128, activation='relu'),\n",
        "                          keras.layers.Dropout(0.15),\n",
        "                          keras.layers.Dense(units=128, activation='relu'),\n",
        "                          keras.layers.Dropout(0.15),\n",
        "                          keras.layers.Dense(units=1)]) # linear output layer for regression\n",
        "opt = keras.optimizers.Adam(learning_rate=0.002)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='mse',\n",
        "              metrics=[keras.metrics.RootMeanSquaredError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe1m0S_waVzT"
      },
      "source": [
        "The following hyperparameter values were evaluated, which all resulted in test data RMSE results in the range of 0.21 to 0.29:\n",
        "* number of Dense layers: 1, 2, 3\n",
        "* number of units per layer: 64, 128\n",
        "* optimizer 'adam' and 'sgd'\n",
        "* keras.layers.Dropout() between layer of 0, 0.1, 0.15, or 0.2\n",
        "* keras.layers.BatchNormalization() between each layer\n",
        "* training batch size of 16, 24, 32\n",
        "* keras.callbacks.ReduceLROnPlateau()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBXXzkIsRRaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ce2111-d491-4da9-de8b-d100056aabf3"
      },
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(patience=20,\n",
        "                                               restore_best_weights=True)\n",
        "lr_schedule = keras.callbacks.ReduceLROnPlateau(factor=0.5,\n",
        "                                                min_lr=1e-6)\n",
        "history = model.fit(X_train, y_train,\n",
        "    batch_size = 32, \t# number of examples in each batch before step\n",
        "    epochs = 500, \t\t# will cycle through all trg data 500 times unless:\n",
        "    callbacks=[early_stopping, lr_schedule], # put callbacks in a list; use lg epochs value\n",
        "    validation_data = (X_val, y_val)) # to monitor performance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "276/276 [==============================] - 2s 4ms/step - loss: 0.1219 - root_mean_squared_error: 0.3491 - val_loss: 0.0844 - val_root_mean_squared_error: 0.2905 - lr: 0.0020\n",
            "Epoch 2/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0955 - root_mean_squared_error: 0.3091 - val_loss: 0.0823 - val_root_mean_squared_error: 0.2869 - lr: 0.0020\n",
            "Epoch 3/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0908 - root_mean_squared_error: 0.3013 - val_loss: 0.0863 - val_root_mean_squared_error: 0.2938 - lr: 0.0020\n",
            "Epoch 4/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0873 - root_mean_squared_error: 0.2954 - val_loss: 0.0848 - val_root_mean_squared_error: 0.2912 - lr: 0.0020\n",
            "Epoch 5/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0858 - root_mean_squared_error: 0.2929 - val_loss: 0.0803 - val_root_mean_squared_error: 0.2834 - lr: 0.0020\n",
            "Epoch 6/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0845 - root_mean_squared_error: 0.2907 - val_loss: 0.0790 - val_root_mean_squared_error: 0.2810 - lr: 0.0020\n",
            "Epoch 7/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0830 - root_mean_squared_error: 0.2881 - val_loss: 0.0761 - val_root_mean_squared_error: 0.2758 - lr: 0.0020\n",
            "Epoch 8/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0812 - root_mean_squared_error: 0.2850 - val_loss: 0.0733 - val_root_mean_squared_error: 0.2708 - lr: 0.0020\n",
            "Epoch 9/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0797 - root_mean_squared_error: 0.2823 - val_loss: 0.0784 - val_root_mean_squared_error: 0.2801 - lr: 0.0020\n",
            "Epoch 10/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0814 - root_mean_squared_error: 0.2852 - val_loss: 0.0709 - val_root_mean_squared_error: 0.2662 - lr: 0.0020\n",
            "Epoch 11/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0783 - root_mean_squared_error: 0.2798 - val_loss: 0.0701 - val_root_mean_squared_error: 0.2648 - lr: 0.0020\n",
            "Epoch 12/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0782 - root_mean_squared_error: 0.2796 - val_loss: 0.0697 - val_root_mean_squared_error: 0.2639 - lr: 0.0020\n",
            "Epoch 13/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0767 - root_mean_squared_error: 0.2770 - val_loss: 0.0677 - val_root_mean_squared_error: 0.2602 - lr: 0.0020\n",
            "Epoch 14/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0762 - root_mean_squared_error: 0.2761 - val_loss: 0.0757 - val_root_mean_squared_error: 0.2751 - lr: 0.0020\n",
            "Epoch 15/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0753 - root_mean_squared_error: 0.2744 - val_loss: 0.0668 - val_root_mean_squared_error: 0.2585 - lr: 0.0020\n",
            "Epoch 16/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0763 - root_mean_squared_error: 0.2762 - val_loss: 0.0659 - val_root_mean_squared_error: 0.2568 - lr: 0.0020\n",
            "Epoch 17/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0762 - root_mean_squared_error: 0.2761 - val_loss: 0.0680 - val_root_mean_squared_error: 0.2608 - lr: 0.0020\n",
            "Epoch 18/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0731 - root_mean_squared_error: 0.2703 - val_loss: 0.0665 - val_root_mean_squared_error: 0.2579 - lr: 0.0020\n",
            "Epoch 19/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0732 - root_mean_squared_error: 0.2705 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2545 - lr: 0.0020\n",
            "Epoch 20/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0715 - root_mean_squared_error: 0.2673 - val_loss: 0.0653 - val_root_mean_squared_error: 0.2555 - lr: 0.0020\n",
            "Epoch 21/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0714 - root_mean_squared_error: 0.2672 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2565 - lr: 0.0020\n",
            "Epoch 22/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0720 - root_mean_squared_error: 0.2684 - val_loss: 0.0639 - val_root_mean_squared_error: 0.2527 - lr: 0.0020\n",
            "Epoch 23/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0703 - root_mean_squared_error: 0.2651 - val_loss: 0.0640 - val_root_mean_squared_error: 0.2530 - lr: 0.0020\n",
            "Epoch 24/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0707 - root_mean_squared_error: 0.2659 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2523 - lr: 0.0020\n",
            "Epoch 25/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0708 - root_mean_squared_error: 0.2661 - val_loss: 0.0638 - val_root_mean_squared_error: 0.2526 - lr: 0.0020\n",
            "Epoch 26/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0697 - root_mean_squared_error: 0.2639 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2550 - lr: 0.0020\n",
            "Epoch 27/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0693 - root_mean_squared_error: 0.2633 - val_loss: 0.0650 - val_root_mean_squared_error: 0.2549 - lr: 0.0020\n",
            "Epoch 28/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0691 - root_mean_squared_error: 0.2629 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2509 - lr: 0.0020\n",
            "Epoch 29/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0682 - root_mean_squared_error: 0.2612 - val_loss: 0.0626 - val_root_mean_squared_error: 0.2501 - lr: 0.0020\n",
            "Epoch 30/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0693 - root_mean_squared_error: 0.2632 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2524 - lr: 0.0020\n",
            "Epoch 31/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0682 - root_mean_squared_error: 0.2612 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2547 - lr: 0.0020\n",
            "Epoch 32/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0670 - root_mean_squared_error: 0.2588 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447 - lr: 0.0020\n",
            "Epoch 33/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0666 - root_mean_squared_error: 0.2580 - val_loss: 0.0621 - val_root_mean_squared_error: 0.2492 - lr: 0.0020\n",
            "Epoch 34/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0668 - root_mean_squared_error: 0.2585 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2456 - lr: 0.0020\n",
            "Epoch 35/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0657 - root_mean_squared_error: 0.2563 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2432 - lr: 0.0020\n",
            "Epoch 36/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0659 - root_mean_squared_error: 0.2568 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2439 - lr: 0.0020\n",
            "Epoch 37/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0657 - root_mean_squared_error: 0.2564 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2449 - lr: 0.0020\n",
            "Epoch 38/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0655 - root_mean_squared_error: 0.2560 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445 - lr: 0.0020\n",
            "Epoch 39/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0651 - root_mean_squared_error: 0.2551 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2424 - lr: 0.0020\n",
            "Epoch 40/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0648 - root_mean_squared_error: 0.2545 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2449 - lr: 0.0020\n",
            "Epoch 41/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0649 - root_mean_squared_error: 0.2548 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451 - lr: 0.0020\n",
            "Epoch 42/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0638 - root_mean_squared_error: 0.2525 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2421 - lr: 0.0020\n",
            "Epoch 43/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0629 - root_mean_squared_error: 0.2508 - val_loss: 0.0573 - val_root_mean_squared_error: 0.2395 - lr: 0.0020\n",
            "Epoch 44/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0630 - root_mean_squared_error: 0.2509 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2434 - lr: 0.0020\n",
            "Epoch 45/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0635 - root_mean_squared_error: 0.2519 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2404 - lr: 0.0020\n",
            "Epoch 46/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0643 - root_mean_squared_error: 0.2535 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400 - lr: 0.0020\n",
            "Epoch 47/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0629 - root_mean_squared_error: 0.2508 - val_loss: 0.0559 - val_root_mean_squared_error: 0.2365 - lr: 0.0020\n",
            "Epoch 48/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0616 - root_mean_squared_error: 0.2482 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410 - lr: 0.0020\n",
            "Epoch 49/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0625 - root_mean_squared_error: 0.2500 - val_loss: 0.0560 - val_root_mean_squared_error: 0.2367 - lr: 0.0020\n",
            "Epoch 50/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0624 - root_mean_squared_error: 0.2498 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2378 - lr: 0.0020\n",
            "Epoch 51/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0619 - root_mean_squared_error: 0.2488 - val_loss: 0.0558 - val_root_mean_squared_error: 0.2362 - lr: 0.0020\n",
            "Epoch 52/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0620 - root_mean_squared_error: 0.2489 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2380 - lr: 0.0020\n",
            "Epoch 53/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0612 - root_mean_squared_error: 0.2473 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2358 - lr: 0.0020\n",
            "Epoch 54/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0605 - root_mean_squared_error: 0.2460 - val_loss: 0.0561 - val_root_mean_squared_error: 0.2369 - lr: 0.0020\n",
            "Epoch 55/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0606 - root_mean_squared_error: 0.2462 - val_loss: 0.0561 - val_root_mean_squared_error: 0.2368 - lr: 0.0020\n",
            "Epoch 56/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0598 - root_mean_squared_error: 0.2446 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2321 - lr: 0.0020\n",
            "Epoch 57/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0605 - root_mean_squared_error: 0.2459 - val_loss: 0.0548 - val_root_mean_squared_error: 0.2340 - lr: 0.0020\n",
            "Epoch 58/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0587 - root_mean_squared_error: 0.2422 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2353 - lr: 0.0020\n",
            "Epoch 59/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0599 - root_mean_squared_error: 0.2448 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375 - lr: 0.0020\n",
            "Epoch 60/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0598 - root_mean_squared_error: 0.2445 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - lr: 0.0020\n",
            "Epoch 61/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0596 - root_mean_squared_error: 0.2442 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2351 - lr: 0.0020\n",
            "Epoch 62/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0598 - root_mean_squared_error: 0.2446 - val_loss: 0.0562 - val_root_mean_squared_error: 0.2370 - lr: 0.0020\n",
            "Epoch 63/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0594 - root_mean_squared_error: 0.2437 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2339 - lr: 0.0020\n",
            "Epoch 64/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0580 - root_mean_squared_error: 0.2409 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2322 - lr: 0.0020\n",
            "Epoch 65/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0580 - root_mean_squared_error: 0.2409 - val_loss: 0.0528 - val_root_mean_squared_error: 0.2297 - lr: 0.0020\n",
            "Epoch 66/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0580 - root_mean_squared_error: 0.2409 - val_loss: 0.0559 - val_root_mean_squared_error: 0.2363 - lr: 0.0020\n",
            "Epoch 67/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0584 - root_mean_squared_error: 0.2417 - val_loss: 0.0548 - val_root_mean_squared_error: 0.2342 - lr: 0.0020\n",
            "Epoch 68/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0584 - root_mean_squared_error: 0.2417 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2317 - lr: 0.0020\n",
            "Epoch 69/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0572 - root_mean_squared_error: 0.2392 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2291 - lr: 0.0020\n",
            "Epoch 70/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0567 - root_mean_squared_error: 0.2381 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2324 - lr: 0.0020\n",
            "Epoch 71/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0570 - root_mean_squared_error: 0.2387 - val_loss: 0.0544 - val_root_mean_squared_error: 0.2332 - lr: 0.0020\n",
            "Epoch 72/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0575 - root_mean_squared_error: 0.2399 - val_loss: 0.0532 - val_root_mean_squared_error: 0.2307 - lr: 0.0020\n",
            "Epoch 73/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0568 - root_mean_squared_error: 0.2383 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2280 - lr: 0.0020\n",
            "Epoch 74/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0579 - root_mean_squared_error: 0.2406 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318 - lr: 0.0020\n",
            "Epoch 75/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0560 - root_mean_squared_error: 0.2366 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2275 - lr: 0.0020\n",
            "Epoch 76/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0554 - root_mean_squared_error: 0.2354 - val_loss: 0.0511 - val_root_mean_squared_error: 0.2261 - lr: 0.0020\n",
            "Epoch 77/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0562 - root_mean_squared_error: 0.2371 - val_loss: 0.0539 - val_root_mean_squared_error: 0.2322 - lr: 0.0020\n",
            "Epoch 78/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0560 - root_mean_squared_error: 0.2367 - val_loss: 0.0520 - val_root_mean_squared_error: 0.2281 - lr: 0.0020\n",
            "Epoch 79/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0576 - root_mean_squared_error: 0.2400 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2327 - lr: 0.0020\n",
            "Epoch 80/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0553 - root_mean_squared_error: 0.2351 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2338 - lr: 0.0020\n",
            "Epoch 81/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0548 - root_mean_squared_error: 0.2342 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2318 - lr: 0.0020\n",
            "Epoch 82/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0561 - root_mean_squared_error: 0.2369 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2379 - lr: 0.0020\n",
            "Epoch 83/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0559 - root_mean_squared_error: 0.2365 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2274 - lr: 0.0020\n",
            "Epoch 84/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0550 - root_mean_squared_error: 0.2344 - val_loss: 0.0514 - val_root_mean_squared_error: 0.2267 - lr: 0.0020\n",
            "Epoch 85/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0534 - root_mean_squared_error: 0.2312 - val_loss: 0.0529 - val_root_mean_squared_error: 0.2301 - lr: 0.0020\n",
            "Epoch 86/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0602 - root_mean_squared_error: 0.2454 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2273 - lr: 0.0020\n",
            "Epoch 87/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0527 - root_mean_squared_error: 0.2295 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2215 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0510 - root_mean_squared_error: 0.2259 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0506 - root_mean_squared_error: 0.2249 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2192 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0511 - root_mean_squared_error: 0.2261 - val_loss: 0.0478 - val_root_mean_squared_error: 0.2186 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0502 - root_mean_squared_error: 0.2241 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2201 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0504 - root_mean_squared_error: 0.2245 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2210 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0492 - root_mean_squared_error: 0.2218 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2195 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0501 - root_mean_squared_error: 0.2238 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2204 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0499 - root_mean_squared_error: 0.2234 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2208 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0487 - root_mean_squared_error: 0.2208 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2190 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0485 - root_mean_squared_error: 0.2202 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2195 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0489 - root_mean_squared_error: 0.2212 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2174 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0489 - root_mean_squared_error: 0.2212 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2197 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0502 - root_mean_squared_error: 0.2240 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2209 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0497 - root_mean_squared_error: 0.2228 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2162 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0481 - root_mean_squared_error: 0.2193 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2162 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0482 - root_mean_squared_error: 0.2195 - val_loss: 0.0472 - val_root_mean_squared_error: 0.2172 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0482 - root_mean_squared_error: 0.2194 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2175 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0484 - root_mean_squared_error: 0.2200 - val_loss: 0.0471 - val_root_mean_squared_error: 0.2169 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0483 - root_mean_squared_error: 0.2199 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2153 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0485 - root_mean_squared_error: 0.2202 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2158 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0482 - root_mean_squared_error: 0.2195 - val_loss: 0.0469 - val_root_mean_squared_error: 0.2166 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0480 - root_mean_squared_error: 0.2191 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2160 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0478 - root_mean_squared_error: 0.2187 - val_loss: 0.0459 - val_root_mean_squared_error: 0.2143 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0483 - root_mean_squared_error: 0.2197 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2137 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0477 - root_mean_squared_error: 0.2184 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2137 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0468 - root_mean_squared_error: 0.2164 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2139 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0475 - root_mean_squared_error: 0.2179 - val_loss: 0.0456 - val_root_mean_squared_error: 0.2136 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0468 - root_mean_squared_error: 0.2164 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2164 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0472 - root_mean_squared_error: 0.2172 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0476 - root_mean_squared_error: 0.2181 - val_loss: 0.0468 - val_root_mean_squared_error: 0.2163 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0477 - root_mean_squared_error: 0.2183 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2138 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0483 - root_mean_squared_error: 0.2197 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2150 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0472 - root_mean_squared_error: 0.2172 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2118 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0481 - root_mean_squared_error: 0.2193 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2140 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0468 - root_mean_squared_error: 0.2163 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2123 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0455 - root_mean_squared_error: 0.2133 - val_loss: 0.0454 - val_root_mean_squared_error: 0.2130 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0465 - root_mean_squared_error: 0.2156 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2124 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0462 - root_mean_squared_error: 0.2150 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0466 - root_mean_squared_error: 0.2158 - val_loss: 0.0454 - val_root_mean_squared_error: 0.2131 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.2142 - val_loss: 0.0444 - val_root_mean_squared_error: 0.2106 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0455 - root_mean_squared_error: 0.2134 - val_loss: 0.0454 - val_root_mean_squared_error: 0.2130 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0472 - root_mean_squared_error: 0.2173 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2114 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0463 - root_mean_squared_error: 0.2152 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2112 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0471 - root_mean_squared_error: 0.2171 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2122 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.2142 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2118 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.2143 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2120 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0457 - root_mean_squared_error: 0.2137 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2120 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0461 - root_mean_squared_error: 0.2148 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2127 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0465 - root_mean_squared_error: 0.2157 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0453 - root_mean_squared_error: 0.2128 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0465 - root_mean_squared_error: 0.2155 - val_loss: 0.0446 - val_root_mean_squared_error: 0.2113 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0456 - root_mean_squared_error: 0.2137 - val_loss: 0.0451 - val_root_mean_squared_error: 0.2123 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0452 - root_mean_squared_error: 0.2126 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2126 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0462 - root_mean_squared_error: 0.2149 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2117 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0449 - root_mean_squared_error: 0.2119 - val_loss: 0.0458 - val_root_mean_squared_error: 0.2140 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0461 - root_mean_squared_error: 0.2146 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2146 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2117 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2133 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0448 - root_mean_squared_error: 0.2116 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2120 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0439 - root_mean_squared_error: 0.2094 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2099 - lr: 5.0000e-04\n",
            "Epoch 148/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0430 - root_mean_squared_error: 0.2074 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2086 - lr: 5.0000e-04\n",
            "Epoch 149/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0422 - root_mean_squared_error: 0.2054 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - lr: 5.0000e-04\n",
            "Epoch 150/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0436 - root_mean_squared_error: 0.2088 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - lr: 5.0000e-04\n",
            "Epoch 151/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0428 - root_mean_squared_error: 0.2070 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - lr: 5.0000e-04\n",
            "Epoch 152/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - lr: 5.0000e-04\n",
            "Epoch 153/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0432 - root_mean_squared_error: 0.2078 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089 - lr: 5.0000e-04\n",
            "Epoch 154/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0422 - root_mean_squared_error: 0.2054 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2084 - lr: 5.0000e-04\n",
            "Epoch 155/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0416 - root_mean_squared_error: 0.2039 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - lr: 5.0000e-04\n",
            "Epoch 156/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0420 - root_mean_squared_error: 0.2049 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2075 - lr: 5.0000e-04\n",
            "Epoch 157/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0430 - root_mean_squared_error: 0.2072 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2078 - lr: 5.0000e-04\n",
            "Epoch 158/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0421 - root_mean_squared_error: 0.2053 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 5.0000e-04\n",
            "Epoch 159/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2063 - val_loss: 0.0423 - val_root_mean_squared_error: 0.2058 - lr: 5.0000e-04\n",
            "Epoch 160/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066 - lr: 5.0000e-04\n",
            "Epoch 161/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0417 - root_mean_squared_error: 0.2043 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2082 - lr: 5.0000e-04\n",
            "Epoch 162/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0413 - root_mean_squared_error: 0.2032 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2076 - lr: 5.0000e-04\n",
            "Epoch 163/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2075 - lr: 5.0000e-04\n",
            "Epoch 164/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0426 - root_mean_squared_error: 0.2064 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2083 - lr: 5.0000e-04\n",
            "Epoch 165/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0431 - root_mean_squared_error: 0.2075 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062 - lr: 5.0000e-04\n",
            "Epoch 166/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0427 - root_mean_squared_error: 0.2066 - val_loss: 0.0427 - val_root_mean_squared_error: 0.2066 - lr: 5.0000e-04\n",
            "Epoch 167/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0424 - root_mean_squared_error: 0.2060 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2081 - lr: 5.0000e-04\n",
            "Epoch 168/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064 - lr: 5.0000e-04\n",
            "Epoch 169/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0415 - root_mean_squared_error: 0.2038 - val_loss: 0.0428 - val_root_mean_squared_error: 0.2068 - lr: 5.0000e-04\n",
            "Epoch 170/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2018 - val_loss: 0.0426 - val_root_mean_squared_error: 0.2064 - lr: 2.5000e-04\n",
            "Epoch 171/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0413 - root_mean_squared_error: 0.2032 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2055 - lr: 2.5000e-04\n",
            "Epoch 172/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2017 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2050 - lr: 2.5000e-04\n",
            "Epoch 173/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0408 - root_mean_squared_error: 0.2021 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060 - lr: 2.5000e-04\n",
            "Epoch 174/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0410 - root_mean_squared_error: 0.2026 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2053 - lr: 2.5000e-04\n",
            "Epoch 175/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0414 - root_mean_squared_error: 0.2034 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2053 - lr: 2.5000e-04\n",
            "Epoch 176/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0408 - root_mean_squared_error: 0.2020 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2054 - lr: 2.5000e-04\n",
            "Epoch 177/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2011 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2053 - lr: 2.5000e-04\n",
            "Epoch 178/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0403 - root_mean_squared_error: 0.2007 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052 - lr: 2.5000e-04\n",
            "Epoch 179/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0403 - root_mean_squared_error: 0.2007 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2050 - lr: 2.5000e-04\n",
            "Epoch 180/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2059 - lr: 2.5000e-04\n",
            "Epoch 181/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0410 - root_mean_squared_error: 0.2024 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2059 - lr: 2.5000e-04\n",
            "Epoch 182/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0412 - root_mean_squared_error: 0.2029 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2048 - lr: 2.5000e-04\n",
            "Epoch 183/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0390 - root_mean_squared_error: 0.1974 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052 - lr: 1.2500e-04\n",
            "Epoch 184/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0401 - root_mean_squared_error: 0.2003 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2052 - lr: 1.2500e-04\n",
            "Epoch 185/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0401 - root_mean_squared_error: 0.2003 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2046 - lr: 1.2500e-04\n",
            "Epoch 186/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0401 - root_mean_squared_error: 0.2002 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2048 - lr: 1.2500e-04\n",
            "Epoch 187/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0398 - root_mean_squared_error: 0.1995 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049 - lr: 1.2500e-04\n",
            "Epoch 188/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2010 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045 - lr: 1.2500e-04\n",
            "Epoch 189/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0408 - root_mean_squared_error: 0.2019 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2044 - lr: 1.2500e-04\n",
            "Epoch 190/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0402 - root_mean_squared_error: 0.2006 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2048 - lr: 1.2500e-04\n",
            "Epoch 191/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0395 - root_mean_squared_error: 0.1989 - val_loss: 0.0419 - val_root_mean_squared_error: 0.2046 - lr: 1.2500e-04\n",
            "Epoch 192/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0406 - root_mean_squared_error: 0.2014 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049 - lr: 1.2500e-04\n",
            "Epoch 193/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0398 - root_mean_squared_error: 0.1995 - val_loss: 0.0421 - val_root_mean_squared_error: 0.2051 - lr: 1.2500e-04\n",
            "Epoch 194/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0402 - root_mean_squared_error: 0.2005 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2051 - lr: 1.2500e-04\n",
            "Epoch 195/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.2009 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2044 - lr: 1.2500e-04\n",
            "Epoch 196/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0398 - root_mean_squared_error: 0.1995 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2049 - lr: 6.2500e-05\n",
            "Epoch 197/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0400 - root_mean_squared_error: 0.2000 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2046 - lr: 6.2500e-05\n",
            "Epoch 198/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0390 - root_mean_squared_error: 0.1975 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - lr: 6.2500e-05\n",
            "Epoch 199/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0398 - root_mean_squared_error: 0.1996 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - lr: 6.2500e-05\n",
            "Epoch 200/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1982 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - lr: 6.2500e-05\n",
            "Epoch 201/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0392 - root_mean_squared_error: 0.1980 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2041 - lr: 6.2500e-05\n",
            "Epoch 202/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0388 - root_mean_squared_error: 0.1971 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041 - lr: 6.2500e-05\n",
            "Epoch 203/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0400 - root_mean_squared_error: 0.2000 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042 - lr: 6.2500e-05\n",
            "Epoch 204/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0383 - root_mean_squared_error: 0.1957 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 6.2500e-05\n",
            "Epoch 205/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0388 - root_mean_squared_error: 0.1970 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042 - lr: 6.2500e-05\n",
            "Epoch 206/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0400 - root_mean_squared_error: 0.1999 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041 - lr: 6.2500e-05\n",
            "Epoch 207/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0394 - root_mean_squared_error: 0.1984 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041 - lr: 6.2500e-05\n",
            "Epoch 208/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0389 - root_mean_squared_error: 0.1972 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041 - lr: 6.2500e-05\n",
            "Epoch 209/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0395 - root_mean_squared_error: 0.1988 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - lr: 6.2500e-05\n",
            "Epoch 210/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0398 - root_mean_squared_error: 0.1995 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - lr: 6.2500e-05\n",
            "Epoch 211/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0402 - root_mean_squared_error: 0.2006 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045 - lr: 6.2500e-05\n",
            "Epoch 212/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0399 - root_mean_squared_error: 0.1996 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042 - lr: 6.2500e-05\n",
            "Epoch 213/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0401 - root_mean_squared_error: 0.2004 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041 - lr: 6.2500e-05\n",
            "Epoch 214/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0394 - root_mean_squared_error: 0.1984 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039 - lr: 6.2500e-05\n",
            "Epoch 215/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039 - lr: 3.1250e-05\n",
            "Epoch 216/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039 - lr: 3.1250e-05\n",
            "Epoch 217/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0397 - root_mean_squared_error: 0.1992 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 218/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0391 - root_mean_squared_error: 0.1976 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 219/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0391 - root_mean_squared_error: 0.1978 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 220/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0401 - root_mean_squared_error: 0.2003 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 221/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 222/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0390 - root_mean_squared_error: 0.1976 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 223/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 3.1250e-05\n",
            "Epoch 224/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0390 - root_mean_squared_error: 0.1974 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2041 - lr: 3.1250e-05\n",
            "Epoch 225/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0383 - root_mean_squared_error: 0.1957 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n",
            "Epoch 226/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0393 - root_mean_squared_error: 0.1983 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n",
            "Epoch 227/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0389 - root_mean_squared_error: 0.1972 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2041 - lr: 1.5625e-05\n",
            "Epoch 228/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0391 - root_mean_squared_error: 0.1978 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2039 - lr: 1.5625e-05\n",
            "Epoch 229/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0400 - root_mean_squared_error: 0.1999 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n",
            "Epoch 230/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0391 - root_mean_squared_error: 0.1977 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2041 - lr: 1.5625e-05\n",
            "Epoch 231/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n",
            "Epoch 232/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0392 - root_mean_squared_error: 0.1980 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n",
            "Epoch 233/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0392 - root_mean_squared_error: 0.1980 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n",
            "Epoch 234/500\n",
            "276/276 [==============================] - 1s 3ms/step - loss: 0.0391 - root_mean_squared_error: 0.1978 - val_loss: 0.0416 - val_root_mean_squared_error: 0.2040 - lr: 1.5625e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud9PePMHaFJt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "02eb068c-4e71-420a-e480-a6995e0eb94a"
      },
      "source": [
        "history_df = pd.DataFrame(history.history) # convert the trg history to a DF\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "history_df.loc[1:, ['loss', 'val_loss']].plot(ax=ax)\n",
        "ax.set(title='Neural Net Learning Curve', xlabel='Epoch', \n",
        "       ylabel='Mean Squared Error');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ev8z4hLivrS"
      },
      "source": [
        "We can see that the model starts to overtrain the training data set at a certain point in the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RaLxzJKZfM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1e3df2-e183-48db-c95b-5be3e035f98c"
      },
      "source": [
        "# Calculate the Standard Deviation of y\n",
        "y_var = float(df1[var['y']].var())\n",
        "print(\"The Variance of the Reproduction Rate (the dependent variable) is {:.4f}\".format(y_var))\n",
        "print(\"The Standard Deviation of the Reproduction Rate (the dependent variable) is {:.4f}\".format(np.sqrt(y_var)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Variance of the Reproduction Rate (the dependent variable) is 0.0959\n",
            "The Standard Deviation of the Reproduction Rate (the dependent variable) is 0.3097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTe6zC8FWDZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8d90ea-567f-4e14-9cce-f0e3f1178541"
      },
      "source": [
        "mse = model.evaluate(X_test, y_test)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 0s 1ms/step - loss: 0.0478 - root_mean_squared_error: 0.2187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thf8o9vrdoKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37efda3-12e6-4ffc-ba8c-7c3b7c673c55"
      },
      "source": [
        "print('{:.1f}% of the variance in the Reproduction Rate is explained by this model'.format(100*(y_var - mse)/y_var))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.1% of the variance in the Reproduction Rate is explained by this model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9WqfDi1fu6W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}